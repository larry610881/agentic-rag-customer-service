# RAG 聊天機器人調整策略（不微調、不壓縮模型）

> 在不對 LLM 進行 Fine-tuning 或模型壓縮的前提下，以下為所有可調整的維度，依影響力排序。

## 調整維度總覽

```
影響力大 ──────────────────────────────── 影響力小

1. Prompt 工程         ← 改一句話可能準確率差 20%
2. 知識庫內容品質       ← 垃圾進垃圾出
3. Chunk / 檢索策略     ← 撈錯資料，模型再強也沒用
4. Reranker            ← 低成本高收益
5. Agent / Tool 編排   ← 決定能不能處理複雜問題
6. LLM 推論參數        ← 影響比想像中小
7. 後處理 / 護欄       ← 最後一道防線
```

---

## 1. Prompt 工程（影響力：極高）

最低成本、最高槓桿的調整手段。改一段 System Prompt 就可能讓準確率大幅提升。

| 調整項 | 說明 | 調整建議 |
|--------|------|----------|
| System Prompt | 角色設定、回答風格、限制條件 | 明確定義身份、語氣、不准做的事 |
| Few-shot Examples | 在 Prompt 中塞幾組好的問答範例 | 3-5 組覆蓋主要場景即可 |
| Chain-of-Thought | 要不要讓模型先推理再回答 | 複雜問題開啟，簡單問題關閉（省 token） |
| Output Format | JSON / Markdown / 純文字 | 結構化輸出有助後續解析與一致性 |
| Guardrail 指令 | 不確定時說「我不確定」而非瞎掰 | 降低幻覺的最有效手段之一 |
| Context Window 管理 | 放進 prompt 的資訊排列順序 | 重要資訊放前面和後面（Lost in the Middle 效應） |

### 反饋循環建議

- 收集「回答不好」的真實案例 → 分析 prompt 哪裡沒覆蓋到 → 迭代修改
- 建立 Prompt 版本管理（v1, v2...），每次改動都 A/B 測試

---

## 2. 知識庫內容品質（影響力：極高）

RAG 的上限不是模型能力，是你灌進去的資料品質。

| 調整項 | 說明 | 調整建議 |
|--------|------|----------|
| 來源文件品質 | 文件本身是否清晰、結構化 | 模糊的內部文件重寫後再灌入 |
| 去重 / 去噪 | 重複或矛盾的文件干擾檢索 | 定期清理，保留單一權威來源 |
| 補充 Q&A 對 | 針對常錯的題目，直接灌正確答案 | 最快速的「修 bug」方式 |
| 資料更新頻率 | 過期資訊導致錯誤回答 | 建立更新 SOP，標記文件有效期限 |
| Metadata 標記 | 每份文件標記類別、時間、適用範圍 | 幫助檢索時精準篩選 |

---

## 3. Chunk / 檢索策略（影響力：高）

決定 LLM 能「看到」什麼資料，直接影響回答品質。

| 調整項 | 選項 | 適用場景 |
|--------|------|----------|
| **Chunk Size** | 256 / 512 / 1024 tokens | 小 chunk 精準但缺上下文；大 chunk 完整但可能帶噪音 |
| **Chunk Overlap** | 0 / 50 / 100 tokens | 重疊防止語意被切斷 |
| **分段策略** | 固定長度 / 語意分段 / 按標題切 | FAQ → 按問題切；長文 → 語意分段 |
| **Embedding Model** | `text-embedding-3-small` vs `large` | small 便宜快；large 品質好 |
| **Top-K** | 3 / 5 / 10 | K 太小可能漏；K 太大帶入噪音 |
| **相似度門檻** | score < 0.7 丟棄 | 避免把不相關的結果餵給 LLM |
| **Hybrid Search** | 向量 + BM25 關鍵字混合 | 專有名詞、編號等關鍵字搜尋更準 |
| **Metadata Filter** | 依類別、時間、租戶先篩再搜 | 縮小搜尋範圍，提升精準度 |

---

## 4. Reranker（影響力：中高）

在向量搜尋撈回 Top-K 後，用 Cross-Encoder 重新排序，低成本高收益。

| 調整項 | 說明 |
|--------|------|
| 是否啟用 | 向量搜尋撈 Top-20 → Reranker 篩到 Top-5 |
| Reranker 模型 | Cohere Rerank / BGE-Reranker / Cross-Encoder |
| 分數門檻 | Reranker score 低於閾值的也丟棄 |

---

## 5. Agent / Tool 編排（影響力：中）

決定機器人「能做什麼事」，以及遇到複雜問題時的處理能力。

| 調整項 | 說明 | 調整建議 |
|--------|------|----------|
| Tool 設計 | 給 Agent 哪些工具 | Tool description 寫得好，Agent 才知道何時該用 |
| 路由邏輯 | 什麼問題走 RAG、什麼直接回答、什麼呼叫 API | 分類越精準，每條路徑品質越高 |
| 多步推理 | 允許 Agent 自己決定要不要再查一次 | 避免一次查不到就放棄 |
| Fallback 策略 | RAG 沒找到時怎麼辦 | 轉人工 / 換 query 再查 / 誠實說不知道 |

---

## 6. LLM 推論參數（影響力：中低）

通常 UI 上可設定的旋鈕。影響比大家想的小，但仍值得調整。

| 參數 | 預設建議 | 說明 |
|------|---------|------|
| `temperature` | 0.0 ~ 0.3 | 客服場景偏低，要穩定一致的回答 |
| `top_p` | 0.9 | 通常不需要特別調 |
| `max_tokens` | 依場景設定 | 避免回答過長浪費 token |
| `model` 選擇 | 視成本/品質取捨 | GPT-4o vs GPT-4o-mini / Claude Sonnet vs Haiku |

---

## 7. 後處理 / 護欄（影響力：低，但必要）

最後一道防線，防止不適當的回答到達使用者。

| 調整項 | 說明 |
|--------|------|
| 幻覺偵測 | 比對回答與 retrieved context，偵測無中生有 |
| 敏感詞過濾 | 攔截不適當內容，替換為安全回答 |
| Citation 機制 | 強制附上來源出處，使用者可自行驗證 |
| Confidence Score | 信心低的回答標記「僅供參考」 |
| 回應長度控制 | 過長截斷 + 提示使用者追問細節 |

---

## 反饋迭代流程建議

```
收集不佳案例 → 分類問題根因 → 對應調整維度 → 測試驗證 → 部署
     ↑                                              │
     └──────────────────────────────────────────────┘
```

| 問題現象 | 可能根因 | 優先調整 |
|----------|---------|---------|
| 答案完全錯誤 | 檢索到錯誤文件 | Chunk 策略 / Reranker |
| 答案正確但不完整 | Top-K 太小或 chunk 太小 | 加大 K / 加大 chunk |
| 瞎掰不存在的資訊 | 幻覺 | Prompt guardrail / 後處理 |
| 語氣不對 | System Prompt 不夠明確 | Prompt 工程 |
| 找不到明明有的資料 | Embedding 品質或分段問題 | Embedding model / 分段策略 |
| 回應太慢 | 模型太大或 Top-K 太高 | 換小模型 / 降 K |
